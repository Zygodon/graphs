---
title: "igraph notebook 3"
output: html_notebook
---
Following igraph_notebook2. I remain impressed by ideas about the development of traits and co-evolution, e.g.  (*https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2148393/; The modularity of pollination networks; Jens M. Olesen, Jordi Bascompte, Yoko L. Dupont, and Pedro Jordano, 2007*). It occurs to me that there might be cooperative interactions between meadow plants, e.g. sharing mycorrhiza; or short-roots cooperating with deep roots; biochemical exchanges in the soil. Would these show up as short-range interactions between plants? Here I've examined communities based on the pairwise odds-ratio of plants being found in the same quadrat. Would truly short-range interactions show up less strongly in community structures based on pairwise odds-ratio of plants being found in the same assembly (bigger area)?

Load libraries and functions:
```{r message=FALSE, warning=FALSE}
# Libraries
library("RMySQL")
library(tidyverse)
library(networkD3)
library(igraph)
library(plotly)
library(DT)

# Functions
dbDisconnectAll <- function(){
  ile <- length(dbListConnections(MySQL())  )
  lapply( dbListConnections(MySQL()), function(x) dbDisconnect(x) )
  cat(sprintf("%s connection(s) closed.\n", ile))
}

# General SQL query
query <- function(q)
{
  # Remote DB with password
  con <- dbConnect(MySQL(), 
                   user  = "guest",
                   password    = "guest",
                   dbname="meadows",
                   port = 3306,
                   host   = "sxouse.ddns.net")
  rs1 = dbSendQuery(con, q)
  return(as_tibble(fetch(rs1, n=-1)))
  dbDisconnectAll()
}

# Load the database
GetTheData <-  function()
{
  # GET DATA FROM DB
  # Remote DB with password
  con <- dbConnect(MySQL(), 
                   user  = "guest",
                   password    = "guest",
                   dbname="meadows",
                   port = 3306,
                   host   = "sxouse.ddns.net")
  
  
  q <- sprintf('select assembly_id, assembly_name, quadrat_count, community, quadrat_id, quadrat_size, visit_date, records_id, species.species_id, 
    species.species_name from assemblies
      join quadrats on quadrats.assembly_id = assemblies_id
      join visit_dates on quadrats.vd_id = visit_dates.vds_id
      join records on records.quadrat_id = quadrats_id
      join species on species.species_id = records.species_id
      # Two assemblies have 0 quadrat count; exclude A.capillaris_stolonifera;
      # exclude some odd assemblies with no assigned community
    where quadrat_count > 0 and species.species_id != 4 and community is not null
    and quadrat_size = "2x2";') 
  # NOTE: this extract includes "MG5", i.e. some MG5 communities where 
  # the team have not decided
  # on a sub-group.
  
  rs1 = dbSendQuery(con, q)
  return(as_tibble(fetch(rs1, n=-1)))
  dbDisconnectAll()
}

OddsRatio <-  function(d, A, B) # assembly/quadrat data, species_name, species_name
{
  A <- A[1]
  B <- B[1]
  t <- d %>% filter(species_name %in% c(A, B))
  As <- t %>% filter(species_name == A)
  Bs <- t %>% filter(species_name == B)
  j1 <- full_join(As, Bs, by = "id")
  # Get all the assemblies/quadrats, including ones with neither A nor B
  q <- d %>% distinct(id) 
  j2 <- (left_join(q, j1, by = "id") 
         # NOTE: column length q >= column length j1
         %>% mutate(AandB = !is.na(species_name.x) & !is.na(species_name.y))
         %>% mutate(AnotB = !is.na(species_name.x) & is.na(species_name.y))
         %>% mutate(BnotA = !is.na(species_name.y) & is.na(species_name.x))
         %>% mutate(neither = is.na(species_name.x) & is.na(species_name.y)))
  s <- colSums(j2[,4:7])
  # Standard Error https://en.wikipedia.org/wiki/Odds_ratio
  se <- sqrt((1/s[1] + (1/s[2]) + (1/s[3]) + (1/s[4]))) # std error of the log(o_r)
  o_r <- (s[1]*s[4])/(s[2]*s[3])
  ci_low <- exp(log(o_r)-1.96*se)
  ci_high <- exp(log(o_r)+1.96*se)
  retval <- c(o_r, ci_low, ci_high)
  names(retval) <- c("odds_ratio", "ci_low", "ci_high")
  return(retval)
}

quadrat_or_given_assembly <- function(r, marg_x, marg_y, sim_length = 10000, pool_size = 5)
# r: assembly odds ratio
# marg_x: marginal probability for species X
# marg_y: marginal probability for species Y
# sim_length: number of simulated trials
# pool_size: quadrat count per assembly
{
  # https://en.wikipedia.org/wiki/Odds_ratio
  s <- sqrt((1 + (marg_x + marg_y)*(r - 1))^2 + 4*r*(1 - r)*marg_x*marg_y)
  p11 <- ((marg_x + marg_y)*(r-1) - s + 1)/(2*(r-1))
  p10 <- marg_x - p11
  p01 <- marg_y - p11
  p00 <- 1 - marg_y - p10
  # r_check <- (p00*p11)/(p01*p10)
  # sim_length <-  2000
  
  sim <-  tibble(trials = sample(c("X1Y1", "X0Y1", "X1Y0", "X0Y0"), sim_length, 
                                 prob = c(p11, p10, p01, p00), rep=T))
  # For the purpose of this function we don't need the assembly level odds ratio
  # joint_probs <- sim %>% group_by(trials) %>% count()
  # ass_or <-  (joint_probs[1,2]*joint_probs[4,2])/(joint_probs[2,2]*joint_probs[3,2])
  
  # Un-pool the samples, 5 to an "assembly", and assign the hits at random between the 5 "quadrats".
  simXY <- (sim %>% mutate(X = (trials == "X1Y1" | trials == "X1Y0"))
            %>% mutate(Y = (trials == "X1Y1" | trials == "X0Y1")))
  simXY$trial <- as.numeric(rownames(simXY))
  simXY <- simXY %>% select(trial, X, Y)
  
  # Make a tibble to put the quadrat_level simulation in
  quads <- tibble(q=rep(seq(1:pool_size), sim_length))
  quads$ass <- c( 1, 1 + seq(1:(pool_size*sim_length)) %/% pool_size)[1:(pool_size*sim_length)]
  # 1,1,1,1,1;2,2,2,2,2; ...
  # Set X and Y FALSE throughout
  quads$X <- F
  quads$Y <- F
  # If there is a hit for X in "assembly" i, set one of the 5 "quadrats" X to TRUE at random
  # Similarly for Y. No short-range association here.
  for (i in 0:(sim_length-1))
  {
    k <- sample(1:pool_size,1)
    if(simXY$X[i+1]) quads$X[5*i+k] <- TRUE
    k <- sample(1:pool_size,1)
    if(simXY$Y[i+1]) quads$Y[5*i+k] <- TRUE
  }
  
  quads <- quads %>% mutate(X1Y1 = X & Y)
  quads <- quads %>% mutate(X1Y0 = X & !Y)
  quads <- quads %>% mutate(X0Y1 = !X & Y)
  quads <- quads %>% mutate(X0Y0 = !X & !Y)
  csums <- colSums(quads[5:8])
  quad_or <- (csums[1]*csums[4])/(csums[2]*csums[3])
  return (quad_or)
} # end function

# End of functions
```

Load data, note excluding 4x4 quadrats so all this analysis is based on 2x2m quadrats. 
```{r message=FALSE, warning=FALSE}
the_data <- GetTheData()
quadrat_data <- (the_data %>% filter(quadrat_size == "2x2")
             %>% select(quadrat_id, species_name))

```
Making edges for the graph objects. The nodes (vertices) will be plant species, joined together by the fact of sharing a common quadrat. Note the group_by(from, to) followed by summarise(share_2x2 = n()). The weight (share_2x2) is the number of quadrats that share this pait of plants.
```{r message=FALSE, warning=FALSE}
edges <- (full_join(quadrat_data, quadrat_data, by = "quadrat_id")
           %>% rename(from = species_name.x)
           %>% rename(to = species_name.y)
           %>%  select(-quadrat_id)
           %>% group_by(from, to) 
           %>% summarise(share_2x2 = n())
           %>% filter(from != to))
nodes <- distinct(edges, from)
```
The graph made from these edges and nodes (vertices) is huge and contains redundant edges arising from (a) plants always share a quadrat with themselves; and (b) if species A shares a quadrat with species B, then species B shares the quadrat with A. So there are twice as many edges as there need to be. I tried to find ways to eliminate the duplicate edges using my own code; in the end I found it easier to use igraph's simplify function.
```{r message=FALSE, warning=FALSE}
net <- graph_from_data_frame(d = edges, vertices = nodes, directed = F)
n2 <- simplify(net, edge.attr.comb = "ignore")
edges2 <- as_data_frame(n2, what="edges")
```
The next step is to find a way to quantify the strength of the associations between pairs of plants, and to simplify the graph by eliminating weak associations. The weight parameter is perhaps not the most appropriate; I use odds ratio, the ratio of the odds of A in the presence of B and the odds of A in the absence of B (Wikipedia)
```{r message=FALSE, warning=FALSE}
# It's much quicker to read the file than to compute from scratch
if (file.exists("Quadrat_PWOR.csv"))
{
  quadrat_pwor <- read.csv("Quadrat_PWOR.csv") 
} else
{
  n <- length(row.names(edges2))
  quadrat_pwor <- tibble(
    odds_ratio = 1:n,
    ci_low = 1:n,
    ci_high = 1:n)
  for (i in seq_along(row.names(edges2)))
  {
    quadrat_pwor[i,1:3] <- OddsRatio(quadrat_data, edges2$from[i], edges2$to[i])
  }
  write.csv(quadrat_pwor, "Quadrat_PWOR.csv")
}
```
The OddsRatio function calculates approximate confidence intervals as well as the ratio itslef, so now we can simplify things by removing edges where the low (5%) confidence limit is greater than 1 (odds ratio of 1 signifies absolute independence; greater than one is some degree of association. Less than one signifies relative exclusion).
```{r message=FALSE, warning=FALSE}
edges3 <-( bind_cols(edges2, quadrat_pwor)
           %>% filter(!is.infinite(odds_ratio))
           %>% filter(!is.infinite(ci_low))
           %>% filter(!is.infinite(ci_high))
           %>% filter(!is.na(ci_low))
           %>% filter(!is.na(ci_high))
           %>% filter(ci_low > 1))
net2 <- graph_from_data_frame(d = edges3, vertices = nodes, directed = F)
l <- layout.fruchterman.reingold(net2)
plot(net2, layout=l, vertex.size = 2, vertex.label=NA)
```
This graph shows that removing low odds-ratio edges has isolated many species, we need to remove them too.
```{r message=FALSE, warning=FALSE}
# Remove isolated vertices (species)
isolated = which(degree(net2)==0)
net3 = delete.vertices(net2, isolated)
l2 = l[-isolated,]
plot(net3, layout=l2, vertex.size = 5,vertex.label=NA)
```
And now we are in a position to look for evidence of some kind of community structure:

```{r message=FALSE, warning=FALSE}
wc <- cluster_walktrap(net3)
modularity(wc)
plot(wc, net3, layout = l2, vertex.label=NA)
```
Cluster_walktrap finds 5 communities; 1 - 3 are large, 5 is a singleton (Linum_catharticum) and 4 consistes of Fissidens_taxifolius, Oenanthe_pimpinelloides, Plagiomnium_undulatum. Only a single assembly contained corky fruited water dropwort, community 4 is likely driven by that fact.

Calculate assembly level PWOR. Extract assembly_id and species names
```{r message=FALSE, warning=FALSE}
assembly_data <- (the_data %>% filter(quadrat_size == "2x2")
             %>% select(assembly_id, species_name))
```

and then go through the same procedure as with the quadrat level analysis: make a graph and reduce its nodes; calculate assembly level PWOR.
```{r message=FALSE, warning=FALSE}
assembly_edges <- (full_join(assembly_data, assembly_data, by = "assembly_id")
           %>% rename(from = species_name.x)
           %>% rename(to = species_name.y)
           %>%  select(-assembly_id)
           %>% group_by(from, to) 
           %>% summarise(share_2x2 = n())
           %>% filter(from != to))
assembly_nodes <- distinct(assembly_edges, from)

ass_net <- graph_from_data_frame(d = assembly_edges, vertices = assembly_nodes, directed = F)
ass_n2 <- simplify(ass_net, edge.attr.comb = "ignore")
ass_edges2 <- as_data_frame(ass_n2, what="edges")

# It's much quicker to read the file than to compute from scratch
if (file.exists("Assembly_PWOR.csv"))
{
  ass_pwor <- read.csv("Assembly_PWOR.csv") 
} else
{
  n <- length(row.names(ass_edges2))
  ass_pwor <- tibble(
    odds_ratio = 1:n,
    ci_low = 1:n,
    ci_high = 1:n)
  for (i in seq_along(row.names(ass_edges2)))
  {
    ass_pwor[i,1:3] <- OddsRatio(assembly_data, ass_edges2$from[i], ass_edges2$to[i])
  }
  write.csv(ass_pwor, "Assembly_PWOR.csv")
}
ass_edges3 <-( bind_cols(ass_edges2, ass_pwor)
           %>% filter(!is.infinite(odds_ratio))
           %>% filter(!is.infinite(ci_low))
           %>% filter(!is.infinite(ci_high))
           %>% filter(!is.na(ci_low))
           %>% filter(!is.na(ci_high))
           %>% filter(ci_low > 1))
ass_net2 <- graph_from_data_frame(d = ass_edges3, vertices = nodes, directed = F)
ass_l <- layout.fruchterman.reingold(ass_net2)

# Remove isolated vertices (species)
isolated = which(degree(ass_net2)==0)
ass_net3 = delete.vertices(ass_net2, isolated)
ass_l2 = ass_l[-isolated,]
# plot(ass_net3, layout=ass_l2, vertex.size = 5,vertex.label=NA)
ass_wc <- cluster_walktrap(ass_net3)
modularity(ass_wc)
plot(ass_wc, ass_net3, layout = ass_l2, vertex.label=NA)
```
However. Leaving aside the beauty of modularity (which I'm sure I will return to), the purpose here was to investigate whether the pairwise odds_ratios (PWOR) could be used to get evidence for specific short range dependencies. So I will compare pairwise odds_ratios from shared quadrats with pairwise odds_ratios from whole assemblies. On the whole, we expect the assembly level PWOR to be greater than the quadrat level on account of the larger area sampled; there is more chance of two species sharing an assembly. This would not necessarily be the case, however, if (a) both members of a pair were very common - and particularly if they had large values for percentage cover - or (b) there was a specific close-range association between them (not excluded by case "a", of course). So pairs of relatively scarce plants for which PWOR is similar by quadrat and by assembly will be of interest.
```{r message=FALSE, warning=FALSE}
j1 <- left_join(ass_edges3, edges3, by = c("from", "to"), suffix = c(".pooled", ".single"))
j2 <-  (left_join(j1, edges, by = c("from", "to")) 
        %>% filter(share_2x2 >= 20)
        %>% filter(!is.na(odds_ratio.single)))
plt2 <- ggplot(j2, aes(x=log(odds_ratio.pooled), y=log(odds_ratio.single))) +
  geom_errorbar(ymin = log(j2$ci_low.single), ymax = log(j2$odds_ratio.single), size = 0.1, width = 0.1, colour = "green", alpha = 0.6) +
  geom_point(aes(colour = share_2x2, text = paste(from, to, sep=","))) +
  scale_colour_gradient(low = "sienna1", high = "black") +
  geom_smooth(method = "lm") + 
  labs(x = "log(Odds Ratio), assemblies", y = "log(Odds Ratio), quadrats")
plotly::ggplotly(plt2)

```

The graph shows log(odds ratio) for plant pairs that share 20 or more quadrats. I've removed the many cases with fewer shared quadrats (Wikipedia on the confidence intervals: "This is an asymptotic approximation, and will not give a meaningful result if any of the cell counts are very small.") At the moment we are interested mainly in points above the blue regression line, so only the (downwards)5% confidence intervals are shown, to avoid clutter. Points are coloured according to the number of shared 2m x 2m quadrats they represent (share_2x2).

We notice that the most highly shared quadrats - representing joint occurrences of the commoner species - are mainly below the regression line. Why should this be? My expectation was that pairs of commoner plants that shared common habitats would have high odds ratio by quadrat as well as by assembly; there would be relatively little difference between the two.The reverse appears to be the case. So, these could be cases where members of a pair actively exclude each other - which would be just as interesting as what I was looking for, pairs that  occur toghether more frequently than we might expect.

Pairs above the line - pairs for which the chance of finding them together in single quadrats is greater than average - tend to be less frequent (lower count of shared occurrences at the quadrat level;paler coloured points). These tend to be plant pairs for which one or both species are less common. For several of them, the 5% confidence interval for the odds ratio by quadrat is above the regression line, which could be taken as indicating a believably high value, and could be regarded as evidence for short-range specificity; e.g. these plants may be in some kind of symbiotic relationship operating on a scale within 2m x 2m.

Candidates for this relationship extracted and listed in the table below.

```{r message=FALSE, warning=FALSE}
# predict fitted values for each observation in the original dataset
model <- lm(log(odds_ratio.single) ~ log(odds_ratio.pooled), data = j2)
model_fit <- data.frame(predict(model, se = F))
j2 <- bind_cols(j2, model_fit)
candidates <- (filter(j2, log(ci_low.single) > predict.model..se...F.)
               %>% select(from, to, share_2x2))
datatable(candidates)
```
To conclude this notebook, I'll make the PWOR scatter plot like the above, but showing 95% ci to find candidates for (competitive?) exclusion:
```{r message=FALSE, warning=FALSE}
plt3 <- ggplot(j2, aes(x=log(odds_ratio.pooled), y=log(odds_ratio.single))) +
  geom_errorbar(ymax = log(j2$ci_high.single), ymin = log(j2$odds_ratio.single), size = 0.1, width = 0.1, colour = "green", alpha = 0.6) +
  geom_point(aes(colour = share_2x2, text = paste(from, to, sep=","))) +
  scale_colour_gradient(low = "sienna1", high = "black") +
  geom_smooth(method = "lm") + 
  labs(x = "log(Odds Ratio), assemblies", y = "log(Odds Ratio), quadrats")
plotly::ggplotly(plt3)

```
And list pairs for which the 95% ci lies below the regression line:
```{r message=FALSE, warning=FALSE}
# predict fitted values for each observation in the original dataset
candidates2 <- (filter(j2, log(ci_high.single) < predict.model..se...F.)
               %>% select(from, to, share_2x2))
datatable(candidates2)

```
There are more candidates for these short-range negative interactions than there are for the positive interactions (55 to 24).

I'm going to turn now to simulating expected outcomes, using simulated plant pairs with known PWOR but NO short range interactions.

It took a while to get my ideas sorted out, but now I have a function, quadrat_or_given_assembly, that returns the expected quadrat_based odds ratio given assembly level data for a species pair.
