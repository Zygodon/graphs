---
title: 'The River Ouse Project: an exploration of meadow plant associations.'
output:
  html_document: null
  word_document: default
  html_notebook: default
  pdf_document: default
  df_print: paged
---
```{r, echo = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(DT)
```

### INTRODUCTION
This is a minimal account of my activity over the last few weeks (partly during the enforced Corona virus lockdown). I present an overview of my current approach with little explanation and no justification, both of which will have to come later.

I've extracted data from the Meadows data base and looked for inter specific associations, independent of our NVC scores; that is, I'm looking for objective clusters in the data, irrespective of any preconceived ideas about what "ought" to be there. My extracted data includes all the stands (assemblies) that were sampled with just five, 2m x 2m quadrats.

### METHOD
Pairwise species associations are expressed as log(odds ratio) - LOR - and their significance estimated using Fisher's Exact Test (which, in R, has the added benefit of spinning off an Expectation Maximisation estimate of the odds ratio).

Dependencies amongst clusters of mutually associated species are investigated using graph-theoretic community detection algorithms. I explored several, and found that "cluster_leading_eigen" gave what I judge to be the most useful result. The resulting communities are visualised with a hairball diagam.

### RESULTS
After removing invalid values for the odds ratio there are 5749 species pairs in the current data. The log(odds ratio) is normally distributed (Figure 1) with mean 0.54 and standard deviation 1.24 which is significantly different from 0 mean (p< 2.2e-16). I conclude that there are more positively associated pairs in the data than there are negatively associated pairs.
![Figure 1. Log(odds ratio).](LOR histogram.png)

At this point in the analysis there are 146 species, 5749 odds-ratio estimates of a maximum, if the graph were fully connected of 146 * 145 = 21170. The difference is accounted for by the removal of invalid odds ratios either because of too many or too few occurrences of at least one member of the pair. To simplify this analysis, I made two arbitrary decisions. In what follows, I have (1) removed all species pairs for which the Fisher test p >= 0.05 (that is, I have removed the weak correlations); and (2) I have removed the negative correlations, log(odds ratio) < 0. So here, I am examining just the strong positive correlations between species. What remains is 79 species with 488 connections.

The cluster_leading_eigen (CLE) algorithm consistently finds three communities of mutually connected species (Figure 2). This is more conservative than other algorithms I have tested, which in general find similar large communities but also tend to split off three or four extra smaller communities. Modularity is an arbitrary measure of the strength of community association. As a rule of thumb it is said that modularity > 0.3 indicates meaningful organisation; the modularity value for Figure 1 is 0.35.

![Figure 2.](G0 Cluster leading eigen.png)

Community membership shown in Tables 1 .. 3.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
cle_clusters <- read.csv("communities.csv")
cle_clusters[,4] <- as.factor(cle_clusters[,4])
grp1 <- cle_clusters %>% filter(community == 1)
grp2 <- cle_clusters %>% filter(community == 2)
grp3 <- cle_clusters %>% filter(community == 3)
datatable(grp1[,c(2, 4)], caption = "Table 1. Community membership group 1")
datatable(grp2[,c(2, 4)], caption = "Table 2. Community membership group 2")
datatable(grp3[,c(2, 4)], caption = "Table 3. Community membership group 3")
```

### DISCUSSION
The ecologists on the team will want to know (as I do) whether these groupings have any ecological meaning. Your comments welcome! I'm not really qualified to tell, but it rather looks as though community 1 is kind of central MG5-ish, 2 is on the wet side (all the Juncus species), and 3 contains several plants on the acid side e.g. Danthonia. But there will be lots of overlap and probably some unexpected bedfellows. Ultimately it's the ecological meaning that matters, and there is plenty of investigation to do here.

Methodologically, this is still very much the data exploration stage. I need to work on establishing the reality of the supposed communities given the variability in the data. There's a technique called Stochastic Block Model (SBM) that appears to be suited these kind of graph-theoretical results. That's my next call, also I want to eliminate the arbitrary decisions made here (as an example, taking p<0.05 as a threshold for rejecting correlations as "significant" doesn't make much sense in this context).

It might be worth mentioning here that the graph-theoretical community detection algorithms work a bit differently than the more familiar statistical clustering methods like k-means, etc. The more familiar algorithms use some concept of distance (obverse, closeness) such as Euclidean distance or Jaccard distance to identify which items are in some sense "close". The graph theory measures don't primarily use that. Instead, they look at the density of connections. The size of the nodes in Figure 1 is determined by their "degree", that is, the number of connections that each one makes. Groups of nodes (species, in our case) that are densely connected, with relatively few connections going outside the group, are candidate communities. With some of the algorithms, including CLE, it is possible to include "weights" on the links between nodes, which can introduce a kind of "distance" measure into the clustering decisions. I've tried it using a scaled version of log(odds ratio)[^1]  but found (a) it complicates the issue; and (b) it tends to find what I think (with no very good reason) are too many clusters.

Finally, I have ideas about how to examine the relationship between these as you might say "naive" communities with the expectations of the NVC, which will be interesting.

John Pilkington 2020-04-02

j.b.pilkington@gmail.com

[^1]: Seeing that the LOR is not far from ideal normal distribution, I used the probability density function p(lor, mu, sd) - in R speak - where mu is the mean and sd the standard deviation given above. The result is a weight in [0..1]; negative weights not allowed in the clustering algorithms.